<!DOCTYPE html>
<html>

<head>
  <title>Audio Buffer</title>
  <meta charset="UTF-8" />
</head>

<body>
  <div id="AudioDiv">
    <video id="VideoSource" width="1280" height="720" autoplay playsinline muted>
    </video>
  </div>
  <br>
  <div id="DownloadDiv">
    <button id="startNdiStreaming" type="button" name="button" onclick="startNdiStreaming()">Play</button>
    <button id="stopNdiStreaming" type="button" name="button" onclick="stopNdiStreaming()">Pause</button>
    <br>
    <canvas name="Bot" id="Bot" width="960" height="540" hidden></canvas>
  </div>
  <script src="/socket.io/socket.io.js"></script>
  <script src="/static/config.js"></script>
  <script src="https://sdk.amazonaws.com/js/aws-sdk-2.990.0.min.js"></script>
</body>

</html>
<script>
  var canvas = document.getElementById('Bot');
  var ctx = canvas.getContext('2d');
  var audioCtx;
  var mainAudioProcessor;
  var source;
  var videoFlag = false;
  var audioFlag = false;
  const frameRate = 1000 / 15;
  var videoProperties = {
    id: 'v001',
    type: 'video',
    channelName: 'testv',
    xres: canvas.width + '',
    yres: canvas.height + '',
    frameRate: frameRate + ''
  };
  var channelName = 'testv';
  var RoomName, EventId, ExternalUserID, currentRecordingS3Path;
  var recorderFlag = false;
  var s3UploadFlag = false;

  const socket = io.connect();
  const videoSocket = io.connect("http://localhost:8000");
  const audioSocket = io.connect("http://localhost:8001");
  let peerConnection;
  const config = turnConfig;
  let silence = () => {
    let ctx = new AudioContext(),
      oscillator = ctx.createOscillator();
    let dst = oscillator.connect(ctx.createMediaStreamDestination());
    oscillator.start();
    return Object.assign(dst.stream.getAudioTracks()[0], {
      enabled: false
    });
  }
  let black = ({
    width = 1280,
    height = 720
  } = {}) => {
    let canvas = Object.assign(document.createElement("canvas"), {
      width,
      height
    });
    canvas.getContext('2d').fillRect(0, 0, width, height);
    let stream = canvas.captureStream();
    return Object.assign(stream.getVideoTracks()[0], {
      enabled: false
    });
  }
  let blackSilence = () => new MediaStream([black(), silence()]);
  var dummyStream = blackSilence();
  var video = document.getElementById('VideoSource');
  var audioStream = new MediaStream([silence()])

  video.srcObject = dummyStream;
  video.play()

  var stream = canvas.captureStream(30);
  var videoDataChunks = [];
  var audioDataChunks = [];

  videoRecorder = new MediaRecorder(stream, {
    mimeType: "video/webm; codecs=vp9"
  });
  videoRecorder.ondataavailable = handleVideoDataAvailable;

  audioRecorder = new MediaRecorder(audioStream, {
    mimeType: "audio/webm;"
  })
  audioRecorder.ondataavailable = handleAudioDataAvailable;

  socket.on("offer", (id, description) => {
    // if (peerConnection === undefined){
    socket.emit("message", "Offer Received from ID " + id)
    peerConnection = new RTCPeerConnection(config);
    // }

    peerConnection
      .setRemoteDescription(description)
      .then(() => peerConnection.createAnswer())
      .then(sdp => peerConnection.setLocalDescription(sdp))
      .then(() => {
        socket.emit("answer", id, peerConnection.localDescription);
        socket.emit("message", "Answer sent to ID " + id)

      });
    peerConnection.ontrack = handleRemoteStreamAdded
    peerConnection.onicecandidate = event => {
      if (event.candidate) {
        socket.emit("message", "IceCandidate received from ID " + id)
        socket.emit("candidate", id, event.candidate);
        socket.emit("message", "IceCandidate send to ID " + id)

      }
    };
  });

  socket.on("candidate", (id, candidate) => {
    socket.emit("message", "IceCandidate added to config from ID " + id)
    peerConnection
      .addIceCandidate(new RTCIceCandidate(candidate))
      .catch(e => console.error(e));
  });

  socket.on("connect", () => {
    console.log("Connected to socket:::::::::::::::::");
    socket.emit("watcher");
    socket.emit("message", "Senting out watcher message when socket connected!")

  });

  socket.on("broadcaster", () => {
    socket.emit("message", "broadcaster signal received!")
    console.log("Got an incoming connection::::: broadcaster :::");
    socket.emit("watcher");
    socket.emit("message", "Senting out watcher signal!")

    console.log("Sending signal from panel to accept ::::: watcher :::");
  });

  socket.on("channelName", (id, message) => {
    channelName = message
    socket.emit("message", "Updated channelName to ::::::::: " + channelName)
    console.log("Update channelName to :::::::::", channelName);

  })
  socket.on("startRecording", (roomName, eventId, externalUserID, projectId) => {
    socket.emit("message", "startRecording received! " + channelName)
    RoomName = roomName;
    EventId = eventId;
    ExternalUserID = externalUserID;
    recorderFlag = true;
    s3UploadFlag = false;
    currentRecordingS3Path = `project/${projectId}/${eventId}`


    if ((audioRecorder.state != 'recording') && (recorderFlag)) {
      audioRecorder.start();
      console.log("Audio Recording started:::::::::::::");
      socket.emit("message", "Audio recording started! " + channelName)

    }
    if ((videoRecorder.state != 'recording') && (recorderFlag)) {
      videoRecorder.start();
      console.log("Video Recording started:::::::::::::");
      socket.emit("message", "Video recording started! " + channelName)

    }

  })

  socket.on("stopRecording", () => {
    if (recorderFlag) {
      socket.emit("message", "stopRecording received! " + channelName)
    }
    if ((audioRecorder.state == 'recording') && (recorderFlag)) {
      audioRecorder.stop();
      console.log("Audio Recording stopped:::::::::::::");
      socket.emit("message", "Audio recording stopped! " + channelName)

    }
    if ((videoRecorder.state == 'recording') && (recorderFlag)) {
      videoRecorder.stop();
      console.log("Video Recording stopped:::::::::::::");
      socket.emit("message", "Video recording stopped! " + channelName)

    }
    recorderFlag = false;
    s3UploadFlag = true;

  })

  function handleRemoteStreamAdded(event) {
    console.log('Remote stream added.');
    video.srcObject = event.streams[0];
    // video.muted = false
    event.streams[0].getTracks().forEach((track, i) => {
      console.log(i, "Details of newly added track ::::", track, track.getSettings());
    });
    audioStream.getTracks().forEach((track, i) => {
      audioStream.removeTrack(track)
    });
    event.streams[0].getAudioTracks().forEach((track, i) => {
      audioStream.addTrack(track)
    });

    if (audioRecorder.state == 'recording') {
      audioRecorder.stop()
    }
    audioRecorder = new MediaRecorder(audioStream, {
      mimeType: "audio/webm;"
    })

    audioRecorder.start();
    audioRecorder.ondataavailable = handleAudioDataAvailable;
    console.log("Audio Recording started:::::::::::::");
    socket.emit("message", "Audio recording started! " + channelName)

    console.log(typeof source, " Source Type :::::::::::::::");
    if (typeof source !== 'undefined') {
      // audioCtx.close();
      // source = null;
      console.log("Updating Audio Source::::::::::::");
      updateSource(audioStream);
    }
  };

  function startNdiStreaming() {
    videoFlag = true
    audioFlag = true
    sendAudio();
  }

  function stopNdiStreaming() {
    videoFlag = false
    audioFlag = false
  }

  video.addEventListener('play', function() {
    // sendAudio();
    var $this = this; //cache

    (function loop() {
      if (!$this.paused && !$this.ended) {
        ctx.drawImage($this, 0, 0, canvas.width, canvas.height);
        if (videoFlag) {
          const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
          videoProperties.channelName = channelName + '-' + canvas.height + 'p'
          videoProperties.id = channelName + '-' + canvas.height + 'p'
          videoProperties.frameRate = frameRate
          const videoProperty = {
            id: channelName + '-' + canvas.height + 'p',
            channelName: channelName + '-' + canvas.height + 'p',
            frameRate: frameRate,
            data: frame.data,
            type: videoProperties.type,
            xres: videoProperties.xres,
            yres: videoProperties.yres
          }
          videoSocket.emit('video frames', videoProperty);
        }
        setTimeout(loop, frameRate); // drawing at 30fps
      }
    })();
  }, 0);

  function updateSource(audioStream) {
    console.log(typeof audioCtx, "audioCtx Type::::::::::")
    if (typeof audioCtx !== 'undefined'){
      source = audioCtx.createMediaStreamSource(audioStream);
      source.connect(mainAudioProcessor);
      mainAudioProcessor.connect(audioCtx.destination)
      console.log("Audio Source Updated::::::::::::");
    }
  }

  function sendAudio() {
    if (typeof source === 'undefined') {
      audioCtx = new AudioContext({
        sampleRate: 48000,
      });
      console.log("Initializing Audio Context :::::");
      source = audioCtx.createMediaStreamSource(audioStream);
      audioCtx.audioWorklet.addModule("/static/main_audio_processor.js")
        .then(() => {
          mainAudioProcessor = new AudioWorkletNode(audioCtx, "main-audio-processor");
          source.connect(mainAudioProcessor);
          mainAudioProcessor.connect(audioCtx.destination)
          mainAudioProcessor.port.onmessage = (e) => {
            if (audioFlag) {
              // console.log(e.data);
              audioSocket.emit('audio frames', e.data, channelName)
            }
          }
        });
    }
  }

  function handleVideoDataAvailable(event) {
    if (event.data.size > 0) {
      console.log("video data available");
      videoDataChunks.push(event.data);
      if (s3UploadFlag) {
        console.log("startS3VideoUpload");
        startS3VideoUpload(currentRecordingS3Path);
      }
    } else {
      // ...
    }

  }

  function handleAudioDataAvailable(event) {
    if (event.data.size > 0) {
      console.log("audio data available");
      audioDataChunks.push(event.data);
      if (s3UploadFlag) {
        console.log("startS3AudioUpload");
        startS3AudioUpload(currentRecordingS3Path);
      }
    } else {
      // ...
    }

  }

  const upload = async function uploadFilesToS3(extension, path, file, fileName) {
    console.log("Initializing upload to s3:::::::::::");
    socket.emit('message', 'Initializing upload to s3!')

    // CALL API

    // await uploadFilesToS3('webm', 'uploads', file, 'myfile');
    return new Promise(async (resolve, reject) => {
      const bucket = new AWS.S3({
        accessKeyId: "",
        secretAccessKey: "",
        region: "us-east-1"
      });
      const params = {
        Bucket: 'w-call-meeting-files',
        Key: path + "/" + fileName + '.' + extension,
        Body: file
      };
      bucket.upload(params, async (err, data) => {
        if (data) {
          console.log("Video uploaded")
          socket.emit('message', fileName + ' uploaded')
        }
        if (err) {
          console.log("Video upload failed")
          socket.emit('message', fileName+" Upload failed")
          console.log(err);
        }
      })
    })
  }

  function startS3VideoUpload(currentRecordingS3Path) {
    var blob = new Blob(videoDataChunks, {
      type: "video/webm"
    });
    var fileName = channelName + '-video'
    let file = new File([blob], fileName, {
      type: 'video/webm',
      lastModified: Date.now()
    })

    upload('webm', currentRecordingS3Path, file, fileName);
    socket.emit('message', fileName + ' upload Initialized!')
  }

  function startS3AudioUpload(currentRecordingS3Path) {
    var blob = new Blob(audioDataChunks, {
      type: "audio/webm"
    });
    var fileName = channelName + '-audio'
    let file = new File([blob], fileName, {
      type: 'audio/webm',
      lastModified: Date.now()
    })
    upload('webm',currentRecordingS3Path , file, fileName);
    socket.emit('message', fileName + ' upload Initialized!')

  }
</script>
